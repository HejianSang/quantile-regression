{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)
#   for(i in 1:n)
#     for(j in 1:n)
#       V.hat=V.hat+(PIJ[i,j]-PI[i]*PI[j])*z[i]*z[j]/(PIJ[i,j]*PI[i]*PI[j])
#' to estimate the density of y
#   density=bkde(A[,2],kernel="normal")
#   index=min(which(density$x>theta.w))
#   f.theta=(density$y[index]+density$y[index-1])/2
temp=matrix(c(rep(1,N),pop[,1]),N,2)
q.N.bar=mean(temp%*%t(t( r.regression$coef)))
h=2*sqrt(V.hat)
w=max.weight(q,weights,q.N.bar)
f.theta=(Fw(A[,2],theta.w+h,w)-Fw(A[,2],theta.w-h,w))/(2*h)
V.theta=V.hat/f.theta^2
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
var.kernel(pop1,100,0.5,0.5)
#' To calculate the bias of the variance estimate
#' We repeat the procedure 5000 times
#' We get th 5000 theta estimations and variance estimations
#' we use the mean of variance estimations as expected variance
#' we use 50000 theta to calculate v(theta)
r=sapply(1:5000,function(o) var.kernel(pop1,100,0.5,0.5))
E.V.hat=mean(unlist(r[3,]))
V.true=var(unlist(r[1,]))
(E.V.hat-V.true-1)*100
E.V.hat
V.true
quantile(rnorm(10000),probs=0.5)
unlist(r[1,])[1:10]
var(unlist(r[1,]))
mean(unlist(r[2,]))
tau-2*sqrt(V.hat)
sqrt(V.hat)
V.hat
tau+2*sqrt(V.hat)
library(quantreg)
library(mvtnorm)
library(plyr)
library(ggplot2)
library(KernSmooth)
library(rootSolve)
#'The simulation studies were conducted to compare the performance of calibrated
#' quantile estimator to those of direct estimator and difference estimator.
#' Two finite populations of size N = 1000 were generated from bivariate
#' normal distribution respectively. The correlation between two variables in
#' the first population is 0.9 and in the second population is 0.6.
N=1000
pho1=0.6
pho2=0.9
mu=c(0,0)
sigma1=matrix(c(1,pho1,pho1,1),2,2)
sigma2=matrix(c(1,pho2,pho2,1),2,2)
pop1=data.frame(rmvnorm(N,mean=mu,sigma=sigma1))
names(pop1)=c("X","Y")
pop2=data.frame(rmvnorm(N,mean=mu,sigma=sigma2))
names(pop2)=c("X","Y")
#'To use simple random sampling to get n=100 sample
n=100
weighted.quantile=function(y,tau,weight)
{
data=cbind(y=y,weight=weight)
data=data[order(data[,1]),]
data=data.frame(data)
total.weight=sum(weight)
f.hat=cumsum(data$weight)/total.weight
indice=which(f.hat>=tau)
return(data$y[min(indice)])
}
Fw=function(y,theta,weight)
{
sum(weight[y<=as.numeric(theta)])/sum(weight)
}
pop=pop1
n
tau=0.5
tau0=0.5
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
q=r.regression$coef*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
V.hat
tau.L=tau-2*sqrt(V.hat)
tau.U=tau+2*sqrt(V.hat)
tau.L
tau.U
Fw.quant=function(w,tau,tau0,A,pop)
{
N=dim(pop)[1]
r.regression=rq(Y~X,tau=tau0,data=A,weights=w)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
}
weights
A
Fw.quant(weights,tau.L,tau.L,A,pop)
tau.L
Fw.quant=function(w,tau,tau0,A,pop)
{
N=dim(pop)[1]
r.regression=rq(Y~X,tau=tau0,data=A,weights=w)
q.direct=weighted.quantile(A[,2],tau,w)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(w*(r.regression$coef*A[,1])))/N
}
Fw.quant(weights,tau.L,tau.L,A,pop)
pop
A
Fw.quant(weights,tau.L,tau.L,A,pop)
tau.L
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
Fw.quant(weights,tau.L,tau.L,A,pop)
Fw.quant=function(w,tau,tau0,A,pop)
{
N=dim(pop)[1]
r.regression=rq(Y~X,tau=tau0,data=A,weights=w)
q.direct=weighted.quantile(A[,2],tau,w)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(w*(r.regression$coef*A[,1])))/N
theta.w
}
Fw.quant(weights,tau.L,tau.L,A,pop)
theta.U=Fw.quant(weights,tau.U,tau.U,A,pop)
theta.L=Fw.quant(weights,tau.L,tau.L,A,pop)
theta.L
theta.U
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
q=r.regression$coef*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
theta.L=Fw.quant(weights,tau.L,tau.L,A,pop)
theta.U=Fw.quant(weights,tau.U,tau.U,A,pop)
V.theta=(theta.U-theta.L)^2/L
return(list(theta.w=theta.w,V.theta=V.theta))
}
wooddruff(pop1,100,0.5,0.5)
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
q=r.regression$coef*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
theta.L=Fw.quant(weights,tau.L,tau.L,A,pop)
theta.U=Fw.quant(weights,tau.U,tau.U,A,pop)
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.theta=V.theta))
}
wooddruff(pop1,100,0.5,0.5)
quantile(pop1[,2],probs=0.5)
r=sapply(1:5000,function(o) wooddruff(pop1,100,0.5,0.5))
E.V.hat=mean(unlist(r[2,]))
E.V.hat
V.true=var(unlist(r[1,]))
V.true
(E.V.hat/V.true-1)*100
var.kernel=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.N.bar=
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
q=r.regression$coef*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
#   for(i in 1:n)
#     for(j in 1:n)
#       V.hat=V.hat+(PIJ[i,j]-PI[i]*PI[j])*z[i]*z[j]/(PIJ[i,j]*PI[i]*PI[j])
#' to estimate the density of y
#   density=bkde(A[,2],kernel="normal")
#   index=min(which(density$x>theta.w))
#   f.theta=(density$y[index]+density$y[index-1])/2
temp=matrix(c(rep(1,N),pop[,1]),N,2)
q.N.bar=mean(temp%*%t(t( r.regression$coef)))
h=2*sqrt(V.hat)
w=max.weight(q,weights,q.N.bar)
f.theta=(Fw(A[,2],theta.w+h,w)-Fw(A[,2],theta.w-h,w))/(2*h)
V.theta=V.hat/f.theta^2
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
var.kernel(pop1,100,0.5,0.5)
max.weight=function(q,d,q.N.bar)
{
n=length(q)
f=function(lambda)
{
c(sum(d/(lambda[1]+lambda[2]*q))+1,sum((d/(lambda[1]+lambda[2]*q)*q))+q.N.bar)
}
lambda=multiroot(f,start=c(-1,-1),maxiter=100)$root
-d/(lambda[1]+q*lambda[2])
#   w=-d/(lambda[1]+q*lambda[2])
#   w[w<0]=0
#   w
}
var.kernel(pop1,100,0.5,0.5)
quantile(pop1[,2],probs=0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
r1=sapply(1:5000,function(o) var.kernel(pop1,100,0.5,0.5))
E.V.hat1=mean(unlist(r1[3,]))
V.true1=var(unlist(1r[1,]))
(E.V.hat1/V.true1-1)*100
E.V.hat1=mean(unlist(r1[3,]))
V.true1=var(unlist(r1[1,]))
(E.V.hat1/V.true1-1)*100
E.V.hat1
V.true1
E.V.hat
V.true
wooddruff(pop2,100,0.5,0.5)
quantile(pop2[,2],probs=0.5)
wooddruff(pop2,100,0.5,0.5)
r=sapply(1:5000,function(o) wooddruff(pop2,100,0.5,0.5))
E.V.hat=mean(unlist(r[2,]))
V.true=var(unlist(r[1,]))
(E.V.hat/V.true-1)*100
E.V.hat
V.true
E.V.hat/V.true
var(unlist(r[1,]))
mean(unlist(r[2,]))
q.direct=weighted.quantile(A[,2],tau,weights)
q.direct
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
q.direct
quantile(pop[,2],0.5)
theta.w=q.direct+(sum(r.regression$coef*pop[,1])-sum(weights*(r.regression$coef*A[,1])))/N
theta.w
library(quantreg)
library(mvtnorm)
library(plyr)
library(ggplot2)
library(KernSmooth)
library(rootSolve)
N=1000
pho1=0.6
pho2=0.9
mu=c(0,0)
sigma1=matrix(c(1,pho1,pho1,1),2,2)
sigma2=matrix(c(1,pho2,pho2,1),2,2)
pop1=data.frame(rmvnorm(N,mean=mu,sigma=sigma1))
names(pop1)=c("X","Y")
pop2=data.frame(rmvnorm(N,mean=mu,sigma=sigma2))
names(pop2)=c("X","Y")
#'To use simple random sampling to get n=100 sample
n=100
r=sapply(1:5000,function(o) wooddruff(pop2,100,0.2,0.2))
E.V.hat=mean(unlist(r[2,]))
V.true=var(unlist(r[1,]))
(E.V.hat/V.true-1)*100
theta=unlist(r[1,])
summary(theta)
V.true
E.V.hat
qnorm(0.2,0,1)
samples=function(pop,n)
{
N=dim(pop)[1]
index=sample(1:N,n,replace=FALSE)
S=pop
S[!(1:N) %in% index,2]=NA
S
}
A=samples(pop1,100)
head(A)
summary(A[,2])
n=sum(!is.na(A[,2]))
n
N=length(A[,1])
index=sample(1:N,n,replace=FALSE)
sample_data=A
sample_data[!(1:N)%in% index,1]
index=sample(1:N,n,replace=FALSE)
sample_data=A
sample_data[!(1:N)%in% index,1]=NA
head(sample_data)
summary(sample_data)
group=function(a,point)
{
p=length(point)
if(a<=point[1])
return(1)
for(i in 2:p)
{
if(a>point[i-1] & a<=point[i])
return(i)
}
if(a>point[p])
return(p+1)
}
category1=function(y,G)
{
temp=NULL
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G)))
### seprate points
yc=y
for(i in 1:dim(y)[1])
for(j in 1:dim(y)[2])
yc[i,j]=group(y[i,j],temp[j,])
return(group=yc)
}
?quantile
category1=function(y,G)
{
temp=NULL
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
### seprate points
yc=y
for(i in 1:dim(y)[1])
for(j in 1:dim(y)[2])
if(!is.na(yc[i,j]))
yc[i,j]=group(y[i,j],temp[j,])
return(group=yc)
}
temp=category(sample_data,10)
temp=category1(sample_data,10)
y=sample_data
temp=NULL
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
temp=NULL
t=dim(y)[2]
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
G=10
temp=NULL
t=dim(y)[2]
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
temp
yc=y
for(i in 1:dim(y)[1])
for(j in 1:dim(y)[2])
if(!is.na(yc[i,j]))
yc[i,j]=group(y[i,j],temp[j,])
head(yc)
category1=function(y,G)
{
temp=NULL
t=dim(y)[2]
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
### seprate points
yc=y
for(i in 1:dim(y)[1])
for(j in 1:dim(y)[2])
if(!is.na(yc[i,j]))
yc[i,j]=group(y[i,j],temp[j,])
return(group=yc)
}
possible_pat=function(sample_data)
{
G=max(sample_data,na.rm=T)
t=dim(sample_data)[2]
pat=NULL
for( i in 1:dim(sample_data)[1])
{
x=as.numeric(sample_data[i,])
j=which(is.na(x))
r=matrix(rep(x,G),ncol=t,byrow=T)
r[,j]=1:G
colnames(r)=paste("y",1:5,sep="")
pat=rbind(pat,r)
}
pat
}
possible_pat=function(sample_data)
{
G=max(sample_data,na.rm=T)
t=dim(sample_data)[2]
pat=NULL
for( i in 1:dim(sample_data)[1])
{
x=as.numeric(sample_data[i,])
j=which(is.na(x))
r=matrix(rep(x,G),ncol=t,byrow=T)
r[,j]=1:G
pat=rbind(pat,r)
}
pat
}
cate=category1(sample_data,10)
head(cate)
patt=possible_pat(cate)
head(patt)
pat=data.frame(possible_pat(sample_data))
joint_prob=data.frame(pat,prob=rep(1/dim(pat)[1],dim(pat)[1]))
head(joint_prob)
count1=function(y_prime,At)
{
l=length(y_prime)
A=unique(as.numeric(At))
if(!is.na(y_prime[1]))
temp=At[pop_group[At[,1],1]==y_prime[1],1] ### index: to store index which is possible to satisfy this pattern
else temp=A[!A%in%At[,1]]
for(i in 2:l)
{
if(!is.na(y_prime[i]))
{
o=At[pop_group[At[,i],i]==y_prime[i],i]
temp=o[o%in%temp]
}
else
{
S=A[!A%in%At[,i]]
temp=S[S%in% temp]
}
}
return(length(temp))
}
count(c(1,NA),cate)
count1(c(1,NA),cate)
