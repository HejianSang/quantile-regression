PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
#   for(i in 1:n)
#     for(j in 1:n)
#       V.hat=V.hat+(PIJ[i,j]-PI[i]*PI[j])*z[i]*z[j]/(PIJ[i,j]*PI[i]*PI[j])
#' to estimate the density of y
#   density=bkde(A[,2],kernel="normal")
#   index=min(which(density$x>theta.w))
#   f.theta=(density$y[index]+density$y[index-1])/2
temp=matrix(c(rep(1,N),pop[,1]),N,2)
q.N.bar=mean(temp%*%t(t( r.regression$coef)))
h=2*sqrt(V.hat)
w=max.weight(q,weights,q.N.bar)
f.theta1=(Fw(A[,2],theta.w+h,w)-Fw(A[,2],theta.w-h,w))/(2*h)
#' f.theta could be 0
#' That will cause the problem
#   V.theta=V.hat/f.theta^2
density=bkde(A[,2],kernel="normal")
index=min(which(density$x>theta.w))
f.theta=(density$y[index]+density$y[index-1])/2
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta,f.theta1=f.theta1))
}
var.kernel(pop1,100,0.5,0.5)
var.kernel=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.N.bar=mean(r.regression$coef[1]+r.regression$coef[2]*pop[,1])
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<=theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
#   for(i in 1:n)
#     for(j in 1:n)
#       V.hat=V.hat+(PIJ[i,j]-PI[i]*PI[j])*z[i]*z[j]/(PIJ[i,j]*PI[i]*PI[j])
#' to estimate the density of y
#   density=bkde(A[,2],kernel="normal")
#   index=min(which(density$x>theta.w))
#   f.theta=(density$y[index]+density$y[index-1])/2
temp=matrix(c(rep(1,N),pop[,1]),N,2)
q.N.bar=mean(temp%*%t(t( r.regression$coef)))
h=2*sqrt(V.hat)
w=max.weight(q,weights,q.N.bar)
f.theta1=(Fw(A[,2],theta.w+h,w)-Fw(A[,2],theta.w-h,w))/(2*h)
#' f.theta could be 0
#' That will cause the problem
density=bkde(A[,2],kernel="normal")
index=min(which(density$x>theta.w))
f.theta=(density$y[index]+density$y[index-1])/2
V.theta=V.hat/f.theta^2
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta,f.theta1=f.theta1))
}
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
r1=sapply(1:5000,function(o) var.kernel(pop1,100,0.5,0.5))
E.V.hat1=mean(unlist(r1[3,]))
V.true1=var(unlist(r1[1,]))
(E.V.hat1/V.true1-1)*100
Fw.quant=function(w,tau,tau0,A,pop)
{
N=dim(pop)[1]
r.regression=rq(Y~X,tau=tau0,data=A,weights=w)
q.direct=weighted.quantile(A[,2],tau,w)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
theta.w
}
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
theta.L=Fw.quant(weights,tau.L,tau.L,A,pop)
theta.U=Fw.quant(weights,tau.U,tau.U,A,pop)
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
wooddruff(pop2,100,0.5,0.5)
r=sapply(1:5000,function(o) wooddruff(pop2,100,0.2,0.2))
E.V.hat=mean(unlist(r[3,]))
V.true=var(unlist(r[1,]))
(E.V.hat/V.true-1)*100
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
q.direct1=weighted.quantile(A[,2],tau.L,weights)
theta.L=q.direct1+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q.direct2=weighted.quantile(A[,2],tau.U,weights)
theta.U=q.direct1+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
wooddruff(pop2,100,0.5,0.5)
wooddruff(pop1,100,0.5,0.5)
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
q.direct1=weighted.quantile(A[,2],tau.L,weights)
theta.L=q.direct1+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q.direct2=weighted.quantile(A[,2],tau.U,weights)
theta.U=q.direct2+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
wooddruff(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
var.kernel(pop1,100,0.5,0.5)
(E.V.hat1/V.true1-1)*100
Fw.quant=function(w,tau,tau0,A,pop)
{
N=dim(pop)[1]
r.regression=rq(Y~X,tau=tau0,data=A,weights=w)
q.direct=weighted.quantile(A[,2],tau,w)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
theta.w
}
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-2*sqrt(V.hat))
tau.U=as.numeric(tau+2*sqrt(V.hat))
q.direct1=weighted.quantile(A[,2],tau.L,weights)
theta.L=q.direct1+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q.direct2=weighted.quantile(A[,2],tau.U,weights)
theta.U=q.direct2+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
wooddruff(pop1,100,0.5,0.5)
r=sapply(1:5000,function(o) wooddruff(pop2,100,0.2,0.2))
E.V.hat=mean(unlist(r[3,]))
V.true=var(unlist(r[1,]))
(E.V.hat/V.true-1)*100
E.V.hat
V.true
E.V.hat/V.true
wooddruff=function(pop,n,tau,tau0)
{
N=dim(pop)[1]
#' SRS samples
A=pop[sample(1:N,n,replace=FALSE),]
#' quantile regression
weights=rep(N/n,n)
PI=rep(n/N,n)
r.regression=rq(Y~X,tau=tau0,data=A,weights=weights)
q.direct=weighted.quantile(A[,2],tau,weights)
theta.w=q.direct+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(weights*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q=r.regression$coef[1]+r.regression$coef[2]*A[,1]
Den=matrix(0,2,2)
Num=matrix(0,2,1)
for(i in  1:n)
{
Den=Den+weights[i]*matrix(c(1,q[i],q[i],q[i]^2),2,2)
Num=Num+weights[i]*matrix(c(1,q[i]),2,1)*(A[i,2]<theta.w)
}
C=solve(Den)%*%Num
z=(A[,2]<theta.w)-matrix(c(rep(1,n),q),n,2)%*%C
PIJ=matrix(n*(n-1)/N/(N-1),n,n)
diag(PIJ)=1/weights
V.hat=var(z)*(1-n/N)/n
tau.L=as.numeric(tau-1.96*sqrt(V.hat))
tau.U=as.numeric(tau+1.96*sqrt(V.hat))
q.direct1=weighted.quantile(A[,2],tau.L,weights)
theta.L=q.direct1+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
q.direct2=weighted.quantile(A[,2],tau.U,weights)
theta.U=q.direct2+(sum(r.regression$coef[1]+r.regression$coef[2]*pop[,1])-sum(w*(r.regression$coef[1]+r.regression$coef[2]*A[,1])))/N
V.theta=(theta.U-theta.L)^2/4
return(list(theta.w=theta.w,V.hat=V.hat,V.theta=V.theta))
}
wooddruff(pop1,100,0.5,0.5)
r=sapply(1:5000,function(o) wooddruff(pop2,100,0.2,0.2))
E.V.hat=mean(unlist(r[3,]))
V.true=var(unlist(r[1,]))
(E.V.hat/V.true-1)*100
V.true
V.true1
E.V.hat
E.V.hat1
margin.y
load("C:/Users/hjsang/Dropbox/KIM/quantile estimation/quantile-regression/.RData")
margin.y
head(joint_prob)
min((temp$x[min((1:401)[temp$x>d[1]]):401])[cumsum(temp$y[min((1:401)[temp$x>d[1]]):401])*diff>left])
em.est=function(tau,A,M,G)
{
n=sum(!is.na(A[,2]))
N=length(A[,1])
X.pop=category1(A,10)$group[,1]
index=sample(1:N,n,replace=FALSE)
sample_data=A
sample_data[!(1:N)%in% index,1]=NA
cate.all=category1(sample_data,10)
cate=cate.all$group
rotate=sample_data[apply(is.na(sample_data),1,sum)<2,]
rotate.cate=cate[apply(is.na(cate),1,sum)<2,]
pat=data.frame(possible_pat(rotate.cate))
joint_prob=data.frame(pat,prob=rep(1/dim(pat)[1],dim(pat)[1]))
X.pop=sapply(A[,1],function(x) group(x,cate.all$point[1,]))
margin.X=as.numeric(table(X.pop)/N)
joint.prob=EM(M,joint_prob,rotate.cate,cate)
#' Do calibration
#' Use X.margin
cali.weight=margin.X/(sapply(1:G,function(x) sum(joint.prob[joint.prob[,1]==x,"prob"])))
margin.y=NULL
for(j in 1:G)
{
m=0
for(i in 1:G)
{
m=m+cali.weight[i]*sum(joint.prob[joint.prob[,1]==i&joint.prob[,2]==j,"prob"])
}
margin.y=c(margin.y,m)
}
Dist=cumsum(margin.y)
index=max((1:G)[Dist<tau])
left=tau-Dist[index]
#'kernel smooth for group index +1
d=A[cate[,2]==index+1,2]
d=d[!is.na(A[cate[,2]==index+1,2])]
temp=bkde(d,kernel="norm")
diff=temp$x[2]-temp$x[1]
min((temp$x[min((1:401)[temp$x>d[1]]):401])[cumsum(temp$y[min((1:401)[temp$x>d[1]]):401])*diff>left])
}
library(quantreg)
library(mvtnorm)
library(plyr)
library(ggplot2)
library(KernSmooth)
library(rootSolve)
#'The simulation studies were conducted to compare the performance of calibrated
#' quantile estimator to those of direct estimator and difference estimator.
#' Two finite populations of size N = 1000 were generated from bivariate
#' normal distribution respectively. The correlation between two variables in
#' the first population is 0.9 and in the second population is 0.6.
N=1000
pho1=0.6
pho2=0.9
mu=c(0,0)
sigma1=matrix(c(1,pho1,pho1,1),2,2)
sigma2=matrix(c(1,pho2,pho2,1),2,2)
pop1=data.frame(rmvnorm(N,mean=mu,sigma=sigma1))
names(pop1)=c("X","Y")
pop2=data.frame(rmvnorm(N,mean=mu,sigma=sigma2))
names(pop2)=c("X","Y")
#'To use simple random sampling to get n=100 sample
n=100
###############################################################
#' Here is the simple idea
#' We have SRS samples form Population Y
#' And we observe all X
#' First we category the sample y to be 10 groups
#' Then we use SRS to get same sample size for X
#'  Called sample x. We also category x to be 10 groups
#'  Then we use EM algorith to calculate the joint prob P(x=i,y=j)
#'  Calibration is we know that the marginal prob for X
#'  So sum P(x=i,y=j) for x is equal to p_i
samples=function(pop,n)
{
N=dim(pop)[1]
index=sample(1:N,n,replace=FALSE)
S=pop
S[!(1:N) %in% index,2]=NA
S
}
A=samples(pop1,100)
#### This function in put a variable a and the points of segment that is a vector.
### This function return the index which group the a belongs
group=function(a,point)
{
p=length(point)
if(a<=point[1])
return(1)
for(i in 2:p)
{
if(a>point[i-1] & a<=point[i])
return(i)
}
if(a>point[p])
return(p+1)
}
category1=function(y,G)
{
temp=NULL
t=dim(y)[2]
for(i in 1:t)
temp=rbind(temp,quantile(y[,i],probs=seq(1/G,1-1/G,by=1/G),na.rm=T))
### seprate points
yc=y
for(i in 1:dim(y)[1])
for(j in 1:dim(y)[2])
if(!is.na(yc[i,j]))
yc[i,j]=group(y[i,j],temp[j,])
return(list(group=yc,point=temp))
}
### Function to find the poosible patterns in sample.
### This help to reduce the heavy of computation
### Input the sample data which is the sample data we have grouped the miss place we use NA
### Return a complete matrix which is all possible patterns
possible_pat=function(sample_data)
{
G=max(sample_data,na.rm=T)
t=dim(sample_data)[2]
pat=NULL
for( i in 1:dim(sample_data)[1])
{
x=as.numeric(sample_data[i,])
j=which(is.na(x))
r=matrix(rep(x,G),ncol=t,byrow=T)
r[,j]=1:G
pat=rbind(pat,r)
}
pat
}
count=function(y_prime,rotate.cate)
{
y_prime[is.na(y_prime)]=0
temp=apply(rotate.cate,1,function(x)
{
x[is.na(x)]=0
all(x==y_prime)
})
sum(temp)
}
EM=function(maxiter,joint_prob,rotate.cate,cate)
{
G=max(rotate.cate,na.rm=T)
N=dim(cate)[1]
time=dim(cate)[2]
p=dim(joint_prob)[1]
weight=1
for(t in 1:maxiter)
{
joint=sapply(1:p,function(i)
{
y_prime=as.numeric(joint_prob[i,1:time])
nt=count(y_prime,rotate.cate)*weight
for(j in 1:time)
{
if(joint_prob[i,time+1]==0)
break
index=1:time
y_prime=as.numeric(joint_prob[i,1:time])
y_prime[j]=NA
index=index[-j]
if(count(y_prime,rotate.cate)!=0)
{
nplus=count(y_prime,rotate.cate)*weight*joint_prob[i,time+1]/ifelse(
sum(joint_prob[sapply(joint_prob[,index],function(x) all(x==y_prime[index])),time+1])==0,1,
sum(joint_prob[sapply(joint_prob[,index],function(x) all(x==y_prime[index])),time+1]))
}
else nplus=0
nt=nt+nplus
}
return(nt)
})
#     if(sum((joint-joint_prob$prob)^2)<0.1)
#       break
joint_prob$prob=joint/sum(joint)
cat("total=",sum(joint),"\n")
cat("t=",t,"\n")
}
return(joint_prob)
}
em.est=function(tau,A,M,G)
{
n=sum(!is.na(A[,2]))
N=length(A[,1])
X.pop=category1(A,10)$group[,1]
index=sample(1:N,n,replace=FALSE)
sample_data=A
sample_data[!(1:N)%in% index,1]=NA
cate.all=category1(sample_data,10)
cate=cate.all$group
rotate=sample_data[apply(is.na(sample_data),1,sum)<2,]
rotate.cate=cate[apply(is.na(cate),1,sum)<2,]
pat=data.frame(possible_pat(rotate.cate))
joint_prob=data.frame(pat,prob=rep(1/dim(pat)[1],dim(pat)[1]))
X.pop=sapply(A[,1],function(x) group(x,cate.all$point[1,]))
margin.X=as.numeric(table(X.pop)/N)
joint.prob=EM(M,joint_prob,rotate.cate,cate)
#' Do calibration
#' Use X.margin
cali.weight=margin.X/(sapply(1:G,function(x) sum(joint.prob[joint.prob[,1]==x,"prob"])))
margin.y=NULL
for(j in 1:G)
{
m=0
for(i in 1:G)
{
m=m+cali.weight[i]*sum(joint.prob[joint.prob[,1]==i&joint.prob[,2]==j,"prob"])
}
margin.y=c(margin.y,m)
}
Dist=cumsum(margin.y)
index=max((1:G)[Dist<tau])
left=tau-Dist[index]
#'kernel smooth for group index +1
d=A[cate[,2]==index+1,2]
d=d[!is.na(A[cate[,2]==index+1,2])]
temp=bkde(d,kernel="norm")
diff=temp$x[2]-temp$x[1]
min((temp$x[min((1:401)[temp$x>d[1]]):401])[cumsum(temp$y[min((1:401)[temp$x>d[1]]):401])*diff>left])
}
em.est(0.5,A,20,10)
